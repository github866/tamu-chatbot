{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  langchain langchain-community langchain-ollama langchain-experimental neo4j tiktoken yfiles_jupyter_graphs python-dotenv json-repair langchain-openai langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "from typing import List\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from neo4j import GraphDatabase\n",
    "from pydantic import BaseModel, Field\n",
    "import warnings\n",
    "\n",
    "#LangChain imports\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_request(url):\n",
    "  return requests.get(url).json()\n",
    "\n",
    "def strip_html(text):\n",
    "  \"\"\" remove HTML tags from a string \"\"\"\n",
    "  if not isinstance(text, str):\n",
    "    return \"\"\n",
    "  clean = re.compile(\"<.*?>\")\n",
    "  return re.sub(clean, \"\", text)\n",
    "\n",
    "def preprocess_events(events):\n",
    "  \"\"\" construct dictionary from event data \"\"\"\n",
    "  return [\n",
    "    {\n",
    "      \"title\": event[\"title\"],\n",
    "      \"group_title\": event[\"group_title\"],\n",
    "      \"url\": event[\"url\"],\n",
    "      \"description\": strip_html(event[\"description\"]),\n",
    "      \"date\": event[\"date\"],\n",
    "      \"date_time\": event[\"date_time\"],\n",
    "      \"location\": event[\"location\"],\n",
    "      \"location_title\": event[\"location_title\"],\n",
    "      \"location_latitude\": float(event[\"location_latitude\"]) if event[\"location_latitude\"] != None else 0,\n",
    "      \"location_longitude\": float(event[\"location_longitude\"]) if event[\"location_longitude\"] != None else 0,\n",
    "      \"cost\": event[\"cost\"],\n",
    "      \"thumbnail\": event[\"thumbnail\"],\n",
    "      \"event_types\": event[\"event_types\"],\n",
    "      \"event_types_audience\": event[\"event_types_audience\"],\n",
    "    }\n",
    "    for event in events\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_root = os.path.join(os.getcwd(), 'graphrag_index')\n",
    "os.makedirs(os.path.join(index_root, 'input'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamu_events_url = \"https://calendar.tamu.edu/live/json/events/group\"\n",
    "raw_events = get_json_request(tamu_events_url)\n",
    "processed_events = preprocess_events(raw_events)\n",
    "\n",
    "#save processed data to file\n",
    "file_path = \"inputEvents.txt\"\n",
    "with open(file_path, 'w') as file:\n",
    "    for i, event in enumerate(processed_events):\n",
    "        file.write(json.dumps(event) + \"\\n\")\n",
    "        if i == 2:  #remove this line later***************\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_docs = []\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        loaded_docs.append(line.strip())\n",
    "\n",
    "documents = loaded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index already exists or there was an error.\n"
     ]
    }
   ],
   "source": [
    "#set up Neo4j database connection\n",
    "driver = GraphDatabase.driver(\n",
    "    uri=os.environ[\"NEO4J_URI\"],\n",
    "    auth=(os.environ[\"NEO4J_USERNAME\"], os.environ[\"NEO4J_PASSWORD\"])\n",
    ")\n",
    "\n",
    "def create_fulltext_index(tx):\n",
    "    query = '''\n",
    "    CREATE FULLTEXT INDEX `fulltext_entity_id` \n",
    "    FOR (n:Entity) \n",
    "    ON EACH [n.id];\n",
    "    '''\n",
    "    tx.run(query)\n",
    "\n",
    "def create_index():\n",
    "    with driver.session() as session:\n",
    "        session.execute_write(create_fulltext_index)\n",
    "\n",
    "try:\n",
    "    create_index()\n",
    "except:\n",
    "    print(\"The index already exists or there was an error.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityItem(BaseModel):\n",
    "    name: str\n",
    "    type: str\n",
    "\n",
    "class Entities(BaseModel):\n",
    "    names: List[EntityItem] = Field(\n",
    "        ...,\n",
    "        description=\"List of entities with 'name' and 'type', focusing on event-related entities.\"\n",
    "    )\n",
    "    \n",
    "def extract_entities(text):\n",
    "    prompt = f\"\"\"\n",
    "    Find relevant entities in the following text, extracting event title,\n",
    "    speakers, locations, general subject matter, and other event-related entities \n",
    "    for creating a knowledge graph. \n",
    "    Format the output as a JSON list, where each item has 'name' and 'type' keys.\n",
    "    Do not add any extra explanation or commentary, just the output specified above.\n",
    "    Create a list of entities with `name` and `type` fields, ensuring that each entity has a \n",
    "    non-null `name` value. If you can't find the `name`, do not include the entity in the response.\n",
    "\n",
    "    Text: \"{text}\"\n",
    "    \"\"\"\n",
    "    \n",
    "    llm = Ollama(model=\"mistral\", temperature=0.0, num_predict=1000)\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    # print(\"llm response:\")\n",
    "    # print(response)\n",
    "\n",
    "    try:\n",
    "        # print(response.strip())\n",
    "        entities = Entities.parse_obj({\"names\": json.loads(response.strip())})\n",
    "        return entities\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing entities: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "#insert documents with extracted entities into the graph\n",
    "def add_document_to_graph(document, entities):\n",
    "    with driver.session() as session:\n",
    "        for entity in entities.names:\n",
    "            # set the Cypher query with the label based on entity type\n",
    "            query = f\"\"\"\n",
    "            MERGE (e:{entity.type} {{name: $name}})\n",
    "            MERGE (d:Document {{text: $text}})\n",
    "            MERGE (d)-[:MENTIONS]->(e)\n",
    "            \"\"\"\n",
    "            \n",
    "            session.run(query, name=entity.name, text=document)\n",
    "\n",
    "#process documents\n",
    "for doc in documents:\n",
    "    entities = extract_entities(doc)\n",
    "    add_document_to_graph(doc, entities)\n",
    "\n",
    "# print(\"extracted entities:\", entities)\n",
    "# print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 5, column: 13, offset: 152} for query: \"\\n            CALL db.index.fulltext.queryNodes('fulltext_entity_id', $query, {limit:2})\\n            YIELD node, score\\n            WITH node\\n            CALL {\\n                MATCH (node)-[r:MENTIONS]->(neighbor)\\n                RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n                UNION ALL\\n                MATCH (node)<-[r:MENTIONS]-(neighbor)\\n                RETURN neighbor.id + ' - ' + type(r) + ' -> ' + node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 5, column: 13, offset: 152} for query: \"\\n            CALL db.index.fulltext.queryNodes('fulltext_entity_id', $query, {limit:2})\\n            YIELD node, score\\n            WITH node\\n            CALL {\\n                MATCH (node)-[r:MENTIONS]->(neighbor)\\n                RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n                UNION ALL\\n                MATCH (node)<-[r:MENTIONS]-(neighbor)\\n                RETURN neighbor.id + ' - ' + type(r) + ' -> ' + node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggie One Stop is a student service center at Texas A&M University. It provides various services such as registration, financial aid, billing, and academic advising all under one roof. This makes it easier for students to access the help they need in one convenient location. Additionally, Aggie One Stop offers resources like tutoring, career services, and disability services. It's a valuable resource for students at Texas A&M University.\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "llm = Ollama(model=\"mistral\", temperature=0.0, num_predict=150)\n",
    "\n",
    "def graph_retriever(question: str):\n",
    "    result = \"\"\n",
    "    entities = extract_entities(question)  #extract entities from the question\n",
    "    # print(\"extracted entities:\", entities)\n",
    "\n",
    "    for entity in entities.names:\n",
    "        #query the graph for each entity's name\n",
    "        response = driver.session().run(\n",
    "            \"\"\"\n",
    "            CALL db.index.fulltext.queryNodes('fulltext_entity_id', $query, {limit:2})\n",
    "            YIELD node, score\n",
    "            WITH node\n",
    "            CALL {\n",
    "                MATCH (node)-[r:MENTIONS]->(neighbor)\n",
    "                RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\n",
    "                UNION ALL\n",
    "                MATCH (node)<-[r:MENTIONS]-(neighbor)\n",
    "                RETURN neighbor.id + ' - ' + type(r) + ' -> ' + node.id AS output\n",
    "            }\n",
    "            RETURN output LIMIT 50\n",
    "            \"\"\",\n",
    "            {\"query\": entity.name}\n",
    "        )\n",
    "\n",
    "        result += \"\\n\".join([el['output'] for el in response])\n",
    "        \n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following graph data, answer the user's question within 100 words.\n",
    "    Do not mention the graph, just focus on answering the user's question.\n",
    "    '{question}'\n",
    "    \n",
    "    Graph data:\n",
    "    {result}\n",
    "    \"\"\"\n",
    "    \n",
    "    #generate a response using the LLM\n",
    "    llm_response = llm.invoke(prompt).strip()\n",
    "    \n",
    "    return llm_response\n",
    "\n",
    "#test\n",
    "print(graph_retriever(\"Tell me about Aggie One Stop.\"))\n",
    "\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
